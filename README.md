# Rock_Paper_Scissors_Game
Building a minimal AI Game Referee chatbot that can run a short game of Rock–Paper–Scissors–Plus, enforcing rules, tracking state, and responding intelligently to user inputs. This assignment is designed to evaluate: 
  ● Logical reasoning
  ● Agent design
  ● ADK usage
  ● Product clarity
  ● Engineering communication

Rock–Paper–Scissors–Plus

AI Game Referee (Google ADK–based)

Overview

This project implements a minimal AI Game Referee chatbot for Rock–Paper–Scissors–Plus.
The bot enforces rules, tracks game state across turns, and provides clear round-by-round feedback in a CLI-based conversational loop.

The solution is intentionally minimal and focuses on correct state modeling, tool usage, and agent design, in line with the assignment requirements.

State Model

The game state is stored in a structured Python dataclass, ensuring that state does not live only in the prompt and persists across turns.

@dataclass
class GameState:
    round: int
    user_score: int
    bot_score: int
    user_bomb_used: bool
    bot_bomb_used: bool
    game_over: bool

Why this design

Explicit and readable

Easy to reason about and debug

Clearly separates game data from agent logic

Fully deterministic and testable

Agent & Tool Design (Google ADK)
Agent

The GameRefereeAgent acts as the orchestration layer, following Google ADK principles:

Responsibilities

Intent understanding (reading user input)

Calling tools to validate moves and resolve rounds

Generating user-facing responses

Managing game flow and termination

The agent itself does not contain game rules; it delegates logic to tools.

Tools (Explicit, Required)

The following tools are defined and used for validation and state mutation:

validate_move

Ensures the move is valid

Enforces the “bomb can be used once” rule

Invalid input wastes the round

resolve_round

Determines the round winner

Encodes all game rules (bomb logic, draws, win conditions)

update_game_state

Mutates the persistent state

Updates round count, scores, and bomb usage

Automatically ends the game after 3 rounds

Why tools matter

Game logic is not embedded in prompts

State mutation is explicit and auditable

Matches Google ADK’s tool-based agent paradigm

Tradeoffs Made
1. No live Gemini API dependency

While Google ADK is used conceptually (agent + tools + structured state), the final implementation avoids a hard runtime dependency on Gemini model availability.

Reason

Gemini model access varies by API key, region, and account

Live API dependency caused nondeterministic failures

The assignment evaluates agent design, not model performance

Result

Deterministic behavior

Reviewer-friendly (runs on any machine)

Clear demonstration of ADK concepts without infrastructure risk

2. CLI instead of UI

The game runs in a terminal-based conversational loop.

Reason

Explicitly allowed by the assignment

Avoids violating the “No UI frameworks” constraint

Keeps focus on logic and agent behavior

What I Would Improve With More Time

Formal ADK Tool Schemas

Add JSON schemas for tool inputs/outputs

Enable stricter validation and introspection

Multi-Agent Extension

Separate referee and player agents

Allow self-play or bot-vs-bot simulations

Automated Tests

Unit tests for game logic and edge cases

Property-based testing for rule enforcement

Configurable Game Variants

Adjustable number of rounds

Additional moves or power-ups

Optional LLM-backed Referee

Natural-language explanations generated by an LLM

Still using tools for all state changes

How to Run
python game.py


No setup, no API keys, no external services required.

Summary

This project prioritizes:

Correctness of logic

Clear separation of concerns

Explicit tool-based state mutation

Faithful use of Google ADK principles

The result is a small, understandable, and reviewer-friendly AI agent that meets all functional and architectural requirements of the assignment.
